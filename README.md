# MSDS692
Mellors Practicum 1
Summary – Hidden Gems Book Recommender System

The Hidden Gems Book Recommender System was developed to address a key limitation in traditional recommendation engines: the tendency to overemphasize bestsellers while underrepresenting high-quality, lesser-known works. The objective of this project was to design and validate a model that identifies “hidden gems”—books with strong reader reviews but relatively low visibility—and recommend them in response to more familiar, popular titles. In doing so, the system promotes discovery, reader engagement, and catalog depth.

The dataset was constructed by merging Goodreads JSON files (containing book and author metadata) with Amazon Books CSV files (containing reviews and ratings). After integration, the combined dataset encompassed more than 1.9 million unique book records. Significant preprocessing was required, including consolidating duplicate rating fields into unified metrics, resolving missing values for authors and descriptions, and normalizing inconsistent language codes. Advanced text preprocessing was also performed, including tokenization, lemmatization, and stopword removal, to prepare features suitable for natural language processing tasks. The final working dataset included approximately 375,000 hidden gems (books with 50–500 reviews and ratings above 3.5) and 44,000 popular books (titles with more than 1,000 reviews).

The model applied a content-based filtering approach using term frequency–inverse document frequency (TF–IDF) vectorization. Titles, descriptions, and lemmatized keywords were vectorized separately, then weighted and combined into a single representation. Cosine similarity was calculated between the vector representations of popular and hidden gem titles to generate recommendations. This methodology enabled the model to return books that were not only thematically relevant to the input title but also lesser known, fulfilling the project’s objective of surfacing high-quality but underexposed works.

Results demonstrated that the recommender produced coherent and useful recommendations. For example, when queried with a title such as The Great Gatsby, the model returned lesser-known but thematically related works rather than only duplicating variants of the same book. While some challenges, such as duplicate editions and missing metadata, required iterative refinement, the overall system consistently delivered relevant hidden gem suggestions. Validation was conducted both through similarity score distributions and manual evaluation of sample recommendations.

This project demonstrates clear strategic value for readers, publishers, and retailers. For readers, it facilitates the discovery of books that might otherwise remain overlooked, enhancing engagement and satisfaction. For publishers and retailers, it creates an opportunity to highlight catalog items that are high quality but underexposed, broadening consumption beyond bestsellers. Furthermore, the system is highly adaptable and can be scaled beyond books to other media domains, such as films, music, or academic research. Future work will involve expanding into neural text embeddings for deeper semantic modeling, incorporating collaborative filtering for personalization, and developing a lightweight demonstration interface for real-world testing.